2
00:00:03,000 --> 00:00:08,300
So you have learned how to consume APIs
using the request module. 
However

3
00:00:08,310 --> 00:00:11,690
not every website has an API for us to work with. 
So

4
00:00:11,690 --> 00:00:15,320
in situations like that, the only
way to get the data we want

5
00:00:15,330 --> 00:00:18,620
is to parse the HTML behind a Web page, 
get rid

6
00:00:18,620 --> 00:00:22,560
of all the HTML tags, and 
extract the actual data. 
This

7
00:00:22,560 --> 00:00:26,350
technique is called web scraping.
 so we scrape all

8
00:00:26,350 --> 00:00:29,930
the HTML tags and 
get the actual data that we want and

9
00:00:29,930 --> 00:00:32,900
that's what I'm going to show you in this tutorial.
So we're going to write a

10
00:00:32,900 --> 00:00:36,170
program that will extract the
 list of newest questions on

11
00:00:36,170 --> 00:00:39,610
stack overflow dot com. 
We refer to this kind of program as

12
00:00:39,610 --> 00:00:43,050
a Web crawler or a Web spider.
So let me show you how

13
00:00:43,050 --> 00:00:46,500
to build a Web crawler in Python. So

14
00:00:46,500 --> 00:00:50,350
here in a new project,
first we need to install beautiful

15
00:00:50,350 --> 00:00:53,880
soup version four. 
This is a very popular

16
00:00:53,880 --> 00:00:57,540
python package for extracting information from HTML and

17
00:00:57,540 --> 00:01:03,960
XML files. 
So let's go ahead. Beautiful.

18
00:01:04,340 --> 00:01:07,620
We also need to install the requests module to download the Web

19
00:01:07,620 --> 00:01:11,730
page that contains the newest
 questions on Stack overflow. So

20
00:01:11,740 --> 00:01:19,720
pipenv install requests. 
All

21
00:01:19,720 --> 00:01:23,560
right. 
Now let's add a new file here, app dot py.

22
00:01:24,040 --> 00:01:27,250
First let's change our virtual environment, so I'm

23
00:01:27,250 --> 00:01:31,980
going to set that to PyCrawler virtual environment. Let's

24
00:01:31,980 --> 00:01:38,740
install pylint. So

25
00:01:38,750 --> 00:01:42,550
the first step is to download the
 Web page that contains the newest questions.

26
00:01:43,140 --> 00:01:46,650
Let's import the requests module and

27
00:01:46,650 --> 00:01:52,060
then we call get and pass https stack

28
00:01:52,440 --> 00:01:56,730
overflow dot com slash questions. Now

29
00:01:56,730 --> 00:02:00,870
we get the response and store it here. This

30
00:02:00,870 --> 00:02:04,200
response object as you have
 seen before as an attribute called

31
00:02:04,200 --> 00:02:07,560
text. and this returns the HTML content of this Web page.

32
00:02:08,040 --> 00:02:12,050
So using this HTML content
 we can create a beautiful soup.

33
00:02:12,060 --> 00:02:16,240
Let me show you.
So from bs4 let's

34
00:02:16,240 --> 00:02:19,770
import the BeautifulSoup class. Now

35
00:02:19,770 --> 00:02:23,570
here we create a BeautifulSoup object and pass

36
00:02:23,660 --> 00:02:27,160
our HTML content. 
Now here we can get the HTML content from

37
00:02:27,160 --> 00:02:30,340
the Web page on the Internet, but 
we can also read the content of an

38
00:02:30,340 --> 00:02:33,780
HTML file on disk.
BeautifulSoup doesn't care, as

39
00:02:33,780 --> 00:02:37,680
long as we give it a string that 
contains some HTML or XML content,

40
00:02:37,710 --> 00:02:41,460
it's happy. 
Now as the second argument we need to pass the

41
00:02:41,460 --> 00:02:44,860
type of parser. 
Because we're gonna parse on html file, We

42
00:02:44,860 --> 00:02:48,720
should pass html dot parser. And

43
00:02:48,720 --> 00:02:52,360
with this we get a soup object. 
Now

44
00:02:52,360 --> 00:02:56,230
this soup object 
mirrors the structure of our HTML document so

45
00:02:56,230 --> 00:03:00,650
we can easily navigate this document and 
find various elements. 
Now

46
00:03:01,040 --> 00:03:05,050
back here. 
Let's right click on the first question and

47
00:03:05,050 --> 00:03:08,150
inspect it. 
So here's the structure of

48
00:03:08,150 --> 00:03:11,570
our document. 
Here we have an anchor that contains the

49
00:03:11,570 --> 00:03:15,630
title of Our question. 
Now let me expand these

50
00:03:15,630 --> 00:03:19,590
elements here. 
So we have this div with the ID questions and

51
00:03:19,590 --> 00:03:22,730
this is the container for all our questions.
let's look at one of

52
00:03:22,730 --> 00:03:26,120
this questions. 
That's a div with the class question dash

53
00:03:26,120 --> 00:03:29,360
summary, inside of this div we have two

54
00:03:29,360 --> 00:03:32,960
other divs, 
one with the class statscontainer that

55
00:03:32,960 --> 00:03:36,560
includes the number of votes and answers,
and another div

56
00:03:36,560 --> 00:03:39,690
with the class summary that
contains the title and summary of

57
00:03:39,690 --> 00:03:43,070
our question. 
So using our super object, we need to find

58
00:03:43,080 --> 00:03:47,160
all elements with the class 
question dash summary. That's

59
00:03:47,160 --> 00:03:50,590
pretty easy. 
So soup has a method called

60
00:03:50,590 --> 00:03:53,930
select that takes a CSS selector. 
If you're

61
00:03:53,930 --> 00:03:57,570
not familiar with CSS selectors, 
you really need to learn that on your own because

62
00:03:57,570 --> 00:04:01,100
that's beyond the scope of a python course.
But basically a CSS

63
00:04:01,100 --> 00:04:04,650
selector is a string that
 helps us find an element in

64
00:04:04,650 --> 00:04:08,070
an HTML document. 
So here we want to get all elements with

65
00:04:08,070 --> 00:04:11,970
the class question dash summary.
We type dot to

66
00:04:11,970 --> 00:04:16,470
specify a class and then
 the name of the class, question

67
00:04:16,630 --> 00:04:20,030
dash summary. 
This will return a list. 
Let's store

68
00:04:20,030 --> 00:04:23,820
that here. 
Each item in this list is an instance

69
00:04:23,820 --> 00:04:27,410
of the tag class. 
Let me show you.
So I'm going to print the

70
00:04:27,410 --> 00:04:30,680
type of the first question, questions of

71
00:04:30,680 --> 00:04:33,820
zero. 
Let's save the changes. 
Run the

72
00:04:33,820 --> 00:04:37,540
program. 
We get this error: No module named 'bs4',

73
00:04:37,550 --> 00:04:41,480
because Code Runner is using
 the wrong python interpreter. I

74
00:04:41,480 --> 00:04:44,760
showed you how to fix this issue earlier.
 so I'm not going to repeat that here.

75
00:04:44,940 --> 00:04:49,370
nstead I'm going to run this program 
using the terminal. So

76
00:04:49,370 --> 00:04:52,740
python3 app dot py. So

77
00:04:52,740 --> 00:04:56,900
each object in this list is
 an instance of the tag class. In

78
00:04:56,900 --> 00:05:00,590
this case, this tag object
 represents this div here, the

79
00:05:00,590 --> 00:05:03,880
first question. 
Now as you see this element has a couple

80
00:05:03,880 --> 00:05:07,590
of attributes, class and id. 
These attributes

81
00:05:07,590 --> 00:05:10,700
are stored in a dictionary in our tag object. 
Let me

82
00:05:10,700 --> 00:05:14,910
show you. 
So I'm going to print questions

83
00:05:15,050 --> 00:05:18,910
of zero dot attributes. 
Save

84
00:05:18,910 --> 00:05:22,950
the changes. 
Let's run it one more time. So

85
00:05:22,960 --> 00:05:26,150
here we have a dictionary with two key value pairs. 
There's the

86
00:05:26,150 --> 00:05:29,810
first one, class and 
here's the second one. Now

87
00:05:29,810 --> 00:05:33,210
we can easily read these
 attributes using square brackets, so we

88
00:05:33,210 --> 00:05:36,840
don't have to access the attributes dictionary,
we can simply use

89
00:05:36,850 --> 00:05:40,290
square brackets here to get
 the value of the id

90
00:05:40,290 --> 00:05:43,670
attribute. 
Now if this element doesn't have this attribute, we're

91
00:05:43,670 --> 00:05:47,150
going to get an exception.
So a safer way is to call the

92
00:05:47,160 --> 00:05:50,250
get method, get id. 
And we

93
00:05:50,250 --> 00:05:53,430
can optionally supply a default value. So

94
00:05:53,430 --> 00:05:56,780
this is all about the attributes.
Now we need to get the

95
00:05:56,780 --> 00:06:00,760
title for each question.
So back to our HTML document.

96
00:06:01,440 --> 00:06:05,180
Here's our question summary
 inside this day we have this

97
00:06:05,180 --> 00:06:08,820
day with the class summary.
Let's expand that. 
We have an h3

98
00:06:08,820 --> 00:06:11,730
with an anchor that
contains the title of our

99
00:06:11,730 --> 00:06:14,850
question. 
Now look at the class attribute here. The

100
00:06:14,850 --> 00:06:19,150
class of this element is question dash hyperlink. So

101
00:06:19,150 --> 00:06:22,670
back to our code, this tag object also has this

102
00:06:22,670 --> 00:06:26,300
select method, like the soup object,
and here we can pass another

103
00:06:26,300 --> 00:06:31,260
CSS selector, in this case question dash hyperlink

104
00:06:32,140 --> 00:06:36,020
Let's save the changes
Run the program again. This

105
00:06:36,020 --> 00:06:39,380
returns a list of objects.
You can see the first object

106
00:06:39,380 --> 00:06:42,940
here is our anchor.
Now in this particular case,

107
00:06:42,940 --> 00:06:46,090
we know that each question has one title. 
so we don't

108
00:06:46,090 --> 00:06:49,730
need a list here. 
We have another method called

109
00:06:49,740 --> 00:06:52,820
select one that returns
one object instead of a

110
00:06:52,820 --> 00:06:56,070
list. 
And this is more efficient in situations where we know

111
00:06:56,070 --> 00:06:59,610
we're dealing with a single element.
 So we don't waste time searching

112
00:06:59,610 --> 00:07:02,940
the entire document for more items. 
So save

113
00:07:02,940 --> 00:07:06,340
the changes. 
Let's run this one more time. Now

114
00:07:06,340 --> 00:07:09,530
we have one anchor. 
So the next step is to get the

115
00:07:09,530 --> 00:07:14,000
actual text here. 
This is the title of a question. 
This

116
00:07:14,000 --> 00:07:17,960
tag object has a method called get text.

117
00:07:20,040 --> 00:07:23,180
Let's try this so back
 to the terminal. Let's run the

118
00:07:23,180 --> 00:07:27,430
program and here's the title
 of our first question. So

119
00:07:27,430 --> 00:07:30,880
next we need to iterate over all
 the questions and get the title of

120
00:07:30,880 --> 00:07:34,850
each. So for question in

121
00:07:34,850 --> 00:07:39,350
questions. let's print question

122
00:07:39,940 --> 00:07:44,380
that select one and then get text.
 save the changes. Run

123
00:07:44,380 --> 00:07:48,770
the program one more time.
 Here are all the questions Beautiful

124
00:07:48,860 --> 00:07:53,440
. The last step is to
 get the votes for each question. So

125
00:07:53,440 --> 00:07:56,990
back to our HTML document.
 As I told you before. each

126
00:07:56,990 --> 00:08:01,060
question summary has a div
 with the class status container

127
00:08:01,540 --> 00:08:05,360
. Here we have another child
 a div with a class stats

128
00:08:06,240 --> 00:08:12,160
and we've got the votes right here. So

129
00:08:12,840 --> 00:08:17,280
we have a span with
 the class vote count Post. So

130
00:08:17,280 --> 00:08:21,260
similarly. we print question dot select

131
00:08:21,640 --> 00:08:26,090
one. The name of
 the class is Vote count

132
00:08:26,230 --> 00:08:29,880
post and once again we call get

133
00:08:29,880 --> 00:08:33,460
text to get the text
 inside of the span element

134
00:08:34,440 --> 00:08:38,310
save the changes. 
Run
 the program one more time,

135
00:08:38,320 --> 00:08:41,710
and we successfully got all the
 newest questions and their vote on

136
00:08:41,710 --> 00:08:45,320
the first page.
 Now. to get the questions on

137
00:08:45,320 --> 00:08:49,150
page two and onwards. we need
 to follow the same approach. So

138
00:08:49,310 --> 00:08:52,490
first we need to find
 the pagination component on this

139
00:08:52,490 --> 00:08:56,040
page. Here we can
 find the last page. So

140
00:08:56,040 --> 00:08:59,240
we extract that here and
 then run this logic inside of

141
00:08:59,240 --> 00:09:06,000
a loop. 
In this loop, in each iteration, 
we'll get the questions for specific page.

